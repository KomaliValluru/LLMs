{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f62affc",
   "metadata": {},
   "outputs": [],
   "source": "# NLP with Hugging Face Transformers - Comprehensive Tutorial\n# This notebook demonstrates various NLP tasks using the Transformers library\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Install required packages if not already installed\ntry:\n    import transformers\n    import torch\n    import tensorflow as tf\n    print(\"All packages are already installed!\")\nexcept ImportError as e:\n    print(f\"Missing package: {e}\")\n    print(\"Please run: pip install transformers torch tensorflow\")\n    \nprint(f\"Transformers version: {transformers.__version__}\")\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"TensorFlow version: {tf.__version__}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371f3e64",
   "metadata": {},
   "outputs": [],
   "source": "# Additional imports for visualization and utilities\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\n\nprint(\"Additional libraries imported successfully!\")\nprint(f\"Analysis started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
  },
  {
   "cell_type": "markdown",
   "id": "0c03d416",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbab941",
   "metadata": {},
   "outputs": [],
   "source": "from transformers import pipeline\n\n# Initialize sentiment analysis pipeline with explicit model\nprint(\"Initializing Sentiment Analysis Pipeline...\")\ntry:\n    classifier = pipeline(\n        \"sentiment-analysis\", \n        model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n        return_all_scores=False\n    )\n    print(\"Sentiment Analysis pipeline initialized successfully!\")\nexcept Exception as e:\n    print(f\"Error initializing pipeline: {e}\")\n    raise"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39df80",
   "metadata": {},
   "outputs": [],
   "source": "# Test single sentence sentiment analysis\ntest_sentence = 'What a wonderful day'\nresult = classifier(test_sentence)\nprint(f\"Input: '{test_sentence}'\")\nprint(f\"Result: {result}\")\nprint(f\"Confidence: {result[0]['score']:.4f}\")\n\n# Let's also test some edge cases\nedge_cases = [\n    \"This is okay, I guess\",  # neutral\n    \"I love this so much!\",   # very positive\n    \"This is terrible and awful\",  # very negative\n    \"\"  # empty string\n]\n\nprint(\"\\nTesting edge cases:\")\nfor text in edge_cases:\n    if text:  # Skip empty strings\n        try:\n            result = classifier(text)\n            print(f\"'{text}' -> {result[0]['label']} ({result[0]['score']:.4f})\")\n        except Exception as e:\n            print(f\"'{text}' -> Error: {e}\")\n    else:\n        print(\"'(empty string)' -> Skipped\")"
  },
  {
   "cell_type": "markdown",
   "id": "5c71ad04",
   "metadata": {},
   "source": [
    "### Passing Multiple prompts to classifier as list gives output in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209974c",
   "metadata": {},
   "outputs": [],
   "source": "# Batch processing multiple texts\nprompts = [\n    'I hate this book',\n    'I am almost done with my Masters, I have learnt a lot',\n    'I love to spend time with my cat'\n]\n\nprint(\"Processing multiple texts:\")\nresults = classifier(prompts)\n\n# Create a structured analysis\nanalysis_data = []\nfor i, (prompt, result) in enumerate(zip(prompts, results)):\n    analysis_data.append({\n        'Text': prompt,\n        'Label': result['label'],\n        'Confidence': result['score'],\n        'Length': len(prompt.split())\n    })\n\n# Display results in a DataFrame for better visualization\ndf_results = pd.DataFrame(analysis_data)\nprint(df_results)\n\n# Visualize the results\nplt.figure(figsize=(12, 6))\n\n# Plot 1: Confidence scores\nplt.subplot(1, 2, 1)\ncolors = ['red' if label == 'NEGATIVE' else 'green' for label in df_results['Label']]\nplt.bar(range(len(df_results)), df_results['Confidence'], color=colors, alpha=0.7)\nplt.title('Sentiment Analysis Confidence Scores')\nplt.xlabel('Text Index')\nplt.ylabel('Confidence Score')\nplt.xticks(range(len(df_results)), [f'Text {i+1}' for i in range(len(df_results))])\n\n# Plot 2: Text length vs confidence\nplt.subplot(1, 2, 2)\nplt.scatter(df_results['Length'], df_results['Confidence'], \n           c=colors, alpha=0.7, s=100)\nplt.title('Text Length vs Confidence')\nplt.xlabel('Number of Words')\nplt.ylabel('Confidence Score')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "e8e78a04",
   "metadata": {},
   "source": [
    "### Using pre-trained models from HuggingFace\n",
    "I am using it as high level helper and not importing the model directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f5ca24",
   "metadata": {},
   "outputs": [],
   "source": "# Advanced Emotion Detection with RoBERTa\nprint(\"Initializing Emotion Detection Pipeline...\")\n\ntry:\n    emotion_pipe = pipeline(\n        \"text-classification\", \n        model=\"SamLowe/roberta-base-go_emotions\",\n        return_all_scores=True  # Get all emotion probabilities\n    )\n    print(\"Emotion detection pipeline initialized successfully!\")\nexcept Exception as e:\n    print(f\"Error initializing emotion pipeline: {e}\")\n    emotion_pipe = None"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e897488",
   "metadata": {},
   "outputs": [],
   "source": "if emotion_pipe:\n    # Test single emotion detection\n    test_text = 'How ungrateful can you be?'\n    emotion_results = emotion_pipe(test_text)\n    \n    print(f\"Input: '{test_text}'\")\n    print(f\"Top emotion: {emotion_results[0]['label']} (confidence: {emotion_results[0]['score']:.4f})\")\n    \n    # Show top 5 emotions\n    print(\"\\nTop 5 emotions detected:\")\n    for i, result in enumerate(emotion_results[:5]):\n        print(f\"{i+1}. {result['label']}: {result['score']:.4f}\")\n    \n    # Visualize emotion distribution\n    if len(emotion_results) >= 5:\n        top_emotions = emotion_results[:10]  # Top 10 emotions\n        labels = [r['label'] for r in top_emotions]\n        scores = [r['score'] for r in top_emotions]\n        \n        plt.figure(figsize=(12, 6))\n        plt.barh(labels, scores, alpha=0.7)\n        plt.title(f'Emotion Distribution for: \"{test_text}\"')\n        plt.xlabel('Confidence Score')\n        plt.tight_layout()\n        plt.show()\nelse:\n    print(\"Emotion pipeline not available\")"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "235a33e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'disapproval', 'score': 0.6340829133987427},\n",
       " {'label': 'love', 'score': 0.9565239548683167},\n",
       " {'label': 'caring', 'score': 0.8449496626853943},\n",
       " {'label': 'optimism', 'score': 0.39558449387550354}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=['I cannot let it happen','I am feeling loved','I will always be with you','I am going to learn it']\n",
    "pipe(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2de6442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "classifier_summerize=pipeline('summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e091b2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Amidst towering structures and bustling activity, a dynamic tapestry of diverse cultures weaves together . Tall skyscrapers reach for the sky, reflecting ambition and innovation that characterize this urban landscape . Hidden parks provide serene retreats, where nature and tranquility offer respite from the urban buzz .'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_summerize('Amidst towering structures and bustling activity, a dynamic tapestry of diverse cultures weaves together, creating an atmosphere that pulsates with life. Tall skyscrapers reach for the sky, reflecting ambition and innovation that characterize this urban landscape. The aroma of diverse cuisines wafts through the air, inviting passersby to explore a world of flavors. Hidden parks provide serene retreats, where nature and tranquility offer respite from the urban buzz. Artistic murals adorn walls, telling stories of rich history and dynamic present. Street performers captivate audiences, turning sidewalks into stages for impromptu performances. Every corner seems to harbor a secret, a unique story waiting to be discovered by those who venture off the beaten path. As day turns to night, the skyline transforms into a glittering spectacle, lights dancing in reflection on glass facades. In this landscape of contrasts and constant motion, energy is infectious, leaving an indelible imprint on all who become part of its ever-evolving narrative.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3dfd66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-base and revision 686f1db (https://huggingface.co/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d23526d9caa4de289cac28696bedd9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0669052ef77549ef85e3b208bfaad67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3e74b6379242c4a1eac95f135e09da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357bd11a74b144919f959e6d780cd602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb39e7fea61a4e6b9c6c690b2abed86d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18135\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "classifier_translate=pipeline('translation_en_to_fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c82bddfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': \"C'est une bonne journée\"}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_translate(\"It is a good day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8fa932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e844bd0dfc403d901ea08e7b12b50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bbf932ed9ac48bab6e47be3c98aa112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc7650e2dd845cea98d8b440c24e737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0adddb934a46cba13e3d1cc63b2963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc178d3c93db4a05ac7c5418ef09b58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c640215ad54d2da2fd6e9fbd56ccf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier_generate=pipeline(\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cfcf529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Today I am feeling sleepy because I have to do my job, but you know my job is the rest of my life.\\n\\nMy problem is I can't take the risk and the risk isn't there because you know I am a professional.\"}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_generate(\"Today I am feeling sleepy because\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "255ad3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de692033487445984f04ea0a6e99e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0327d4e8a4f4c94b9c64fc5758adbb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6ba3cd49a74f68b3a0f3502ce38d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f0e64a27d440adb1489e597387e144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390d2d87c7e84d65b1277db2bec62901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier_unmask=pipeline(\"fill-mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80df3d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.5158199071884155,\n",
       "  'token': 39,\n",
       "  'token_str': ' his',\n",
       "  'sequence': 'The doctor is unable to make it today because, his car broke down'},\n",
       " {'score': 0.22296088933944702,\n",
       "  'token': 69,\n",
       "  'token_str': ' her',\n",
       "  'sequence': 'The doctor is unable to make it today because, her car broke down'},\n",
       " {'score': 0.056190524250268936,\n",
       "  'token': 5,\n",
       "  'token_str': ' the',\n",
       "  'sequence': 'The doctor is unable to make it today because, the car broke down'},\n",
       " {'score': 0.04049336165189743,\n",
       "  'token': 127,\n",
       "  'token_str': ' my',\n",
       "  'sequence': 'The doctor is unable to make it today because, my car broke down'},\n",
       " {'score': 0.03273928165435791,\n",
       "  'token': 49,\n",
       "  'token_str': ' their',\n",
       "  'sequence': 'The doctor is unable to make it today because, their car broke down'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_unmask(\"The doctor is unable to make it today because, <mask> car broke down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5048090d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\18135\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "classifier_ner=pipeline('ner', grouped_entities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6722dfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9981694,\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9796019,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9932106,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_ner('My name is Sylvain and I work at Hugging Face in Brooklyn.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "001feca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf5dad16959449e89cf3d1986c00e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8c4e41ba084189a9704c0b61ac94fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f871e1456c9442bda1a887c7c72fc809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb435e011e1491c8a485c8a7bd32f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ff24e09d3d4e159c5cb2bac2fca04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier_ques_ans=pipeline('question-answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9bf0a869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.5736246109008789,\n",
       " 'start': 43,\n",
       " 'end': 61,\n",
       " 'answer': 'six thirty evening'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_ques_ans(question='When is my class?', context='Today the class is scheduled in EDU 115 at six thirty evening. Make sure to submit assignment by 10pm.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e885d31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}